{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "src = 'data/training_data_features.csv'\n",
    "training_data = pd.read_csv(src, index_col=0)\n",
    "\n",
    "src = 'data/validation_data_features.csv'\n",
    "validation_data = pd.read_csv(src, index_col=0)\n",
    "\n",
    "src = 'data/test_data_features.csv'\n",
    "test_data = pd.read_csv(src, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier with TF-IDF - Grid Search and Cross Validation optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "### --- Uncomment code below to run --- ###\n",
    "\n",
    "# # TF-IDF Vectorization\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# tfidf_training_matrix = tfidf_vectorizer.fit_transform(training_data['content_stem'])\n",
    "# tfidf_validation_matrix = tfidf_vectorizer.transform(validation_data['content_stem'])\n",
    "\n",
    "# # Target labels\n",
    "# y_training_data = training_data['reliable']\n",
    "# y_validation_data = validation_data['reliable']\n",
    "\n",
    "# # Define the parameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(10,), (20,), (10,10), (20,20)],\n",
    "#     'learning_rate_init': [0.001, 0.01]\n",
    "# }\n",
    "\n",
    "# # Initialize the MLPClassifier (Neural Network)\n",
    "# mlp_model = MLPClassifier(max_iter=500, random_state=42, early_stopping=True, verbose=True)\n",
    "\n",
    "# # Initialize the GridSearchCV object\n",
    "# grid_search = GridSearchCV(mlp_model, param_grid=param_grid, cv=3)\n",
    "\n",
    "# # Fit the GridSearchCV object\n",
    "# grid_search.fit(tfidf_training_matrix, y_training_data)\n",
    "\n",
    "# # Access the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# # Access the best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # Make predictions on the validation data\n",
    "# predictions = best_model.predict(tfidf_validation_matrix)\n",
    "\n",
    "# print(\"BEST MLP CLASSIFIER w/ TF-IDF\")\n",
    "# # Evaluate the MLPClassifier\n",
    "# print(classification_report(y_validation_data, predictions))\n",
    "\n",
    "# # save trained model as persistance\n",
    "# joblib.dump(best_model, 'pickle/best_mlp_model_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier with TF-IDF (with optimal parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# load optimized trained model\n",
    "best_model = joblib.load('pickle/best_mlp_model_tfidf.joblib')\n",
    "\n",
    "# get parameters\n",
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_training_matrix = tfidf_vectorizer.fit_transform(training_data['content_stem'])\n",
    "tfidf_validation_matrix = tfidf_vectorizer.transform(validation_data['content_stem'])\n",
    "\n",
    "# Target labels\n",
    "y_training_data = training_data['reliable']\n",
    "y_validation_data = validation_data['reliable']\n",
    "\n",
    "# # Initialize the MLPClassifier (Neural Network)\n",
    "# mlp_model = MLPClassifier(hidden_layer_sizes=(10), max_iter=500, random_state=42, early_stopping=True, verbose=True)\n",
    "\n",
    "# # Fit the MLPClassifier using TF-IDF features\n",
    "# mlp_model.fit(tfidf_training_matrix, y_training_data)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "mlp_model = best_model\n",
    "predictions = mlp_model.predict(tfidf_validation_matrix)\n",
    "\n",
    "# Evaluate the MLPClassifier\n",
    "print(\"MLP CLASSIFIER w/ TF-IDF\")\n",
    "print(classification_report(y_validation_data, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained TF-IDF vectorizer and MLPClassifier\n",
    "joblib.dump(tfidf_vectorizer, 'pickle/tfidf_vectorizer_mlp.joblib')\n",
    "joblib.dump(mlp_model, 'pickle/mlp_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = joblib.load('pickle/tfidf_vectorizer_mlp.joblib')\n",
    "mlp_model = joblib.load('pickle/best_mlp_model_tfidf.joblib')\n",
    "\n",
    "# TF-IDF transformation on test data\n",
    "tfidf_test_matrix = tfidf_vectorizer.transform(test_data['content_stem'])\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = mlp_model.predict(tfidf_test_matrix)\n",
    "\n",
    "# Evaluate the MLPClassifier\n",
    "print(\"MLP Classifier w/ TF-IDF on Fake News\")\n",
    "print(classification_report(test_data['reliable'], test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_data['reliable'],test_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['false', 'true'])\n",
    "disp.plot()\n",
    "plt.title('MLP CLASSIFIER w/ TF-IDF on Fake News')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on LIAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'data/liar_dataset/test_features.csv'\n",
    "test_data = pd.read_csv(src, index_col=0)\n",
    "\n",
    "# Load the saved vectorizer and model when needed\n",
    "tfidf_vectorizer = joblib.load('pickle/tfidf_vectorizer_mlp.joblib')\n",
    "mlp_model = joblib.load('pickle/mlp_model.joblib')\n",
    "\n",
    "# TF-IDF transformation on test data\n",
    "tfidf_test_matrix = tfidf_vectorizer.transform(test_data['content_stem'])\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = mlp_model.predict(tfidf_test_matrix)\n",
    "\n",
    "# Evaluate the MLPClassifier\n",
    "print(\"MLP CLASSIFIER w/ TF-IDF on LIAR\")\n",
    "print(classification_report(test_data['reliable'], test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_data['reliable'],test_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['false', 'true'])\n",
    "disp.plot()\n",
    "plt.title('MLP CLASSIFIER w/ TF-IDF on LIAR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "# training data\n",
    "src = 'data/training_data_embeddings.csv'\n",
    "training_embeddings = pd.read_csv(src)\n",
    "\n",
    "src = 'data/training_data_features.csv'\n",
    "training_data = pd.read_csv(src)\n",
    "\n",
    "# validation data\n",
    "src = 'data/validation_data_embeddings.csv'\n",
    "validation_embeddings = pd.read_csv(src)\n",
    "\n",
    "src = 'data/validation_data_features.csv'\n",
    "validation_data = pd.read_csv(src)\n",
    "\n",
    "# test data\n",
    "src = 'data/test_data_features.csv'\n",
    "test_data = pd.read_csv(src)\n",
    "\n",
    "src = 'data/test_data_embeddings.csv'\n",
    "test_embeddings = pd.read_csv(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale input features\n",
    "scaler = StandardScaler(with_mean=False)  # Pass with_mean=False for sparse matrices\n",
    "X_training_scaled = scaler.fit_transform(training_embeddings)\n",
    "X_validation_scaled = scaler.transform(validation_embeddings)\n",
    "\n",
    "y_train = training_data['reliable']\n",
    "y_val = validation_data['reliable']\n",
    "\n",
    "# MLP model with 1 hidden layer and 10 neurones, with the default rectified linear unit function.\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10), max_iter=500, random_state=42, batch_size='auto', early_stopping=True, verbose=True)\n",
    "mlp_model.fit(X_training_scaled, y_train)\n",
    "\n",
    "predictions = mlp_model.predict(X_validation_scaled)\n",
    "\n",
    "print(\"MLP CLASSIFIER w/ TRANSFORMER\")\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained scaler and MLPClassifier\n",
    "joblib.dump(scaler, 'pickle/scaler_mlp.joblib')\n",
    "joblib.dump(mlp_model, 'pickle/mlp_model_transformer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved scaler and MLPClassifier when needed\n",
    "scaler = joblib.load('pickle/scaler_mlp.joblib')\n",
    "mlp_model = joblib.load('pickle/mlp_model_transformer.joblib')\n",
    "\n",
    "# Scale test data\n",
    "X_test_scaled = scaler.transform(test_embeddings)\n",
    "y_test = test_data['reliable']\n",
    "# Make predictions on the test data\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the MLPClassifier\n",
    "print(\"MLP CLASSIFIER w/ TRANSFORMER on Fake News\")\n",
    "print(classification_report(y_test, mlp_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, mlp_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['false', 'true'])\n",
    "disp.plot(values_format='')\n",
    "plt.title('MLP CLASSIFIER w/ TRANSFORMER on Fake News')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on LIAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "src = 'data/liar_dataset/test_features.csv'\n",
    "test_data = pd.read_csv(src)\n",
    "\n",
    "src = 'data/liar_dataset/test_embeddings.csv'\n",
    "test_embeddings = pd.read_csv(src)\n",
    "\n",
    "# Load the saved scaler and MLPClassifier when needed\n",
    "scaler = joblib.load('pickle/scaler_mlp.joblib')\n",
    "mlp_model = joblib.load('pickle/mlp_model_transformer.joblib')\n",
    "\n",
    "# Scale test data\n",
    "X_test_scaled = scaler.transform(test_embeddings)\n",
    "y_test = test_data['reliable']\n",
    "# Make predictions on the test data\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the MLPClassifier\n",
    "print(\"MLP CLASSIFIER w/ TRANSFORMER on LIAR\")\n",
    "print(classification_report(y_test, mlp_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, mlp_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['false', 'true'])\n",
    "disp.plot()\n",
    "plt.title('MLP CLASSIFIER w/ TRANSFORMER on LIAR')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
